{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVCOpWlLpBn5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add bias term to the dataset\n",
        "def add_bias(X):\n",
        "   return np.c_[np.ones((X.shape[0], 1)), X]\n",
        "# Train perceptron function\n",
        "def train_perceptron(X, y, epochs=1000, learning_rate=0.1):\n",
        "    weights = np.zeros(X.shape[1])  # Initialize weights\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(len(X)):\n",
        "            if y[i] * np.dot(X[i], weights) <= 0:\n",
        "                weights += learning_rate * y[i] * X[i]\n",
        "    return weights\n",
        "\n",
        "# Binary perceptron prediction function\n",
        "def predict_perceptron(X, weights):\n",
        "    activations = np.dot(X, weights)\n",
        "    return np.where(activations >= 0, 1, -1)\n",
        "\n",
        "# Generate binary classification dataset\n",
        "X, y = make_classification(n_samples=500, n_features=5, n_classes=2, random_state=42)\n",
        "X = add_bias(X)  # Add bias column\n",
        "y = np.where(y == 0, -1, 1)  # Convert to -1 and 1 for perceptron\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gXFh6bGCuIK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.01, 0.05, 0.1, 0.2]\n",
        "epochs = [500, 1000, 1500]\n",
        "\n",
        "# Train perceptron\n",
        "for i in range(len(epochs)):\n",
        "  for j in range(len(learning_rates)):\n",
        "    weights = train_perceptron(X_train, y_train, epochs[i], learning_rates[j])\n",
        "    print(f\"Training with epochs={epochs[i]} and learning_rate={learning_rates[j]}\")\n",
        "    # Predict and evaluate\n",
        "    y_pred = predict_perceptron(X_test, weights)\n",
        "    print(\"Binary Perceptron Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JniYt4NF1LMs",
        "outputId": "36cb68de-3ddc-4164-9ffc-faa1117283d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with epochs=500 and learning_rate=0.01\n",
            "Binary Perceptron Accuracy: 0.8\n",
            "[[40 13]\n",
            " [ 7 40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.85      0.75      0.80        53\n",
            "           1       0.75      0.85      0.80        47\n",
            "\n",
            "    accuracy                           0.80       100\n",
            "   macro avg       0.80      0.80      0.80       100\n",
            "weighted avg       0.81      0.80      0.80       100\n",
            "\n",
            "Training with epochs=500 and learning_rate=0.05\n",
            "Binary Perceptron Accuracy: 0.8\n",
            "[[40 13]\n",
            " [ 7 40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.85      0.75      0.80        53\n",
            "           1       0.75      0.85      0.80        47\n",
            "\n",
            "    accuracy                           0.80       100\n",
            "   macro avg       0.80      0.80      0.80       100\n",
            "weighted avg       0.81      0.80      0.80       100\n",
            "\n",
            "Training with epochs=500 and learning_rate=0.1\n",
            "Binary Perceptron Accuracy: 0.8\n",
            "[[40 13]\n",
            " [ 7 40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.85      0.75      0.80        53\n",
            "           1       0.75      0.85      0.80        47\n",
            "\n",
            "    accuracy                           0.80       100\n",
            "   macro avg       0.80      0.80      0.80       100\n",
            "weighted avg       0.81      0.80      0.80       100\n",
            "\n",
            "Training with epochs=500 and learning_rate=0.2\n",
            "Binary Perceptron Accuracy: 0.8\n",
            "[[40 13]\n",
            " [ 7 40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.85      0.75      0.80        53\n",
            "           1       0.75      0.85      0.80        47\n",
            "\n",
            "    accuracy                           0.80       100\n",
            "   macro avg       0.80      0.80      0.80       100\n",
            "weighted avg       0.81      0.80      0.80       100\n",
            "\n",
            "Training with epochs=1000 and learning_rate=0.01\n",
            "Binary Perceptron Accuracy: 0.89\n",
            "[[43 10]\n",
            " [ 1 46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.98      0.81      0.89        53\n",
            "           1       0.82      0.98      0.89        47\n",
            "\n",
            "    accuracy                           0.89       100\n",
            "   macro avg       0.90      0.90      0.89       100\n",
            "weighted avg       0.90      0.89      0.89       100\n",
            "\n",
            "Training with epochs=1000 and learning_rate=0.05\n",
            "Binary Perceptron Accuracy: 0.89\n",
            "[[43 10]\n",
            " [ 1 46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.98      0.81      0.89        53\n",
            "           1       0.82      0.98      0.89        47\n",
            "\n",
            "    accuracy                           0.89       100\n",
            "   macro avg       0.90      0.90      0.89       100\n",
            "weighted avg       0.90      0.89      0.89       100\n",
            "\n",
            "Training with epochs=1000 and learning_rate=0.1\n",
            "Binary Perceptron Accuracy: 0.89\n",
            "[[43 10]\n",
            " [ 1 46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.98      0.81      0.89        53\n",
            "           1       0.82      0.98      0.89        47\n",
            "\n",
            "    accuracy                           0.89       100\n",
            "   macro avg       0.90      0.90      0.89       100\n",
            "weighted avg       0.90      0.89      0.89       100\n",
            "\n",
            "Training with epochs=1000 and learning_rate=0.2\n",
            "Binary Perceptron Accuracy: 0.89\n",
            "[[43 10]\n",
            " [ 1 46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.98      0.81      0.89        53\n",
            "           1       0.82      0.98      0.89        47\n",
            "\n",
            "    accuracy                           0.89       100\n",
            "   macro avg       0.90      0.90      0.89       100\n",
            "weighted avg       0.90      0.89      0.89       100\n",
            "\n",
            "Training with epochs=1500 and learning_rate=0.01\n",
            "Binary Perceptron Accuracy: 0.88\n",
            "[[43 10]\n",
            " [ 2 45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.81      0.88        53\n",
            "           1       0.82      0.96      0.88        47\n",
            "\n",
            "    accuracy                           0.88       100\n",
            "   macro avg       0.89      0.88      0.88       100\n",
            "weighted avg       0.89      0.88      0.88       100\n",
            "\n",
            "Training with epochs=1500 and learning_rate=0.05\n",
            "Binary Perceptron Accuracy: 0.88\n",
            "[[43 10]\n",
            " [ 2 45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.81      0.88        53\n",
            "           1       0.82      0.96      0.88        47\n",
            "\n",
            "    accuracy                           0.88       100\n",
            "   macro avg       0.89      0.88      0.88       100\n",
            "weighted avg       0.89      0.88      0.88       100\n",
            "\n",
            "Training with epochs=1500 and learning_rate=0.1\n",
            "Binary Perceptron Accuracy: 0.88\n",
            "[[43 10]\n",
            " [ 2 45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.81      0.88        53\n",
            "           1       0.82      0.96      0.88        47\n",
            "\n",
            "    accuracy                           0.88       100\n",
            "   macro avg       0.89      0.88      0.88       100\n",
            "weighted avg       0.89      0.88      0.88       100\n",
            "\n",
            "Training with epochs=1500 and learning_rate=0.2\n",
            "Binary Perceptron Accuracy: 0.88\n",
            "[[43 10]\n",
            " [ 2 45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.96      0.81      0.88        53\n",
            "           1       0.82      0.96      0.88        47\n",
            "\n",
            "    accuracy                           0.88       100\n",
            "   macro avg       0.89      0.88      0.88       100\n",
            "weighted avg       0.89      0.88      0.88       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z))\n",
        "    return exp_z / np.sum(exp_z)\n",
        "\n",
        "# Multiclass perceptron training function using softmax\n",
        "def train_multiclass_softmax(X, y, num_classes, epochs, learning_rate):\n",
        "    weights = np.zeros((num_classes, X.shape[1]))  # Initialize weights\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(X.shape[0]):  # Loop over each sample\n",
        "            xi = X[i]\n",
        "            yi = y[i]\n",
        "            # Compute logits (for all classes) and probabilities\n",
        "            logits = np.dot(weights, xi)\n",
        "            probabilities = softmax(logits)\n",
        "\n",
        "            # Convert label to one-hot encoding\n",
        "            y_one_hot = np.zeros(num_classes)\n",
        "            y_one_hot[yi] = 1\n",
        "\n",
        "            # Update weights for each class\n",
        "            for k in range(num_classes):\n",
        "                gradient = (probabilities[k] - y_one_hot[k]) * xi  # Gradient for class k\n",
        "                weights[k] -= learning_rate * gradient\n",
        "    return weights\n",
        "\n",
        "    # Prediction function for multiclass perceptron using softmax\n",
        "def predict_multiclass_softmax(X, weights):\n",
        "    logits = np.dot(X, weights.T)  # Compute logits for each class\n",
        "    probabilities = softmax(logits)  # Apply softmax to compute class probabilities\n",
        "    return np.argmax(probabilities, axis=1)  # Return the class with highest probability"
      ],
      "metadata": {
        "id": "_qHiINmywHqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiclass Perceptron Dataset"
      ],
      "metadata": {
        "id": "wbRbg32LzGbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Generate multiclass dataset\n",
        "X, y = make_classification(n_samples=500, n_features=5, n_classes=3, n_informative=3, random_state=42)"
      ],
      "metadata": {
        "id": "Q77cfQ4SzEDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = add_bias(X)\n",
        "\n",
        "# Split Dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
        "\n",
        "def predict_multiclass_softmax(X, weights):\n",
        "    logits = np.dot(X, weights.T)  # Compute logits for each class\n",
        "    probabilities = softmax(logits)  # Apply softmax to compute class probabilities\n",
        "    return np.argmax(probabilities, axis=1)  # Return the class with highest probability"
      ],
      "metadata": {
        "id": "-mb0eCk_zW3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.01, 0.05, 0.1, 0.2]\n",
        "epochs_list = [500, 1000, 1500]\n",
        "\n",
        "for i in range(len(epochs)):\n",
        "  for j in range(len(learning_rates)):\n",
        "    # Train multiclass perceptron\n",
        "    num_classes = len(np.unique(y_train))  # Number of unique classes in y_train\n",
        "    weights_softmax = train_multiclass_softmax(X_train, y_train, num_classes, epochs=1000, learning_rate=0.1)\n",
        "    # Predict and evaluate\n",
        "    y_pred_softmax = predict_multiclass_softmax(X_test, weights_softmax)\n",
        "    print(\"Multiclass Perceptron with Softmax Accuracy:\", accuracy_score(y_test, y_pred_softmax))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_softmax))\n",
        "    print(classification_report(y_test, y_pred_softmax))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNFRxAgG1ib9",
        "outputId": "992ac0e5-4389-4a49-ba7e-653076d25486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Perceptron with Softmax Accuracy: 0.64\n",
            "Confusion Matrix:\n",
            " [[22  6  0]\n",
            " [17 12  5]\n",
            " [ 3  5 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        28\n",
            "           1       0.52      0.35      0.42        34\n",
            "           2       0.86      0.79      0.82        38\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.63      0.64      0.62       100\n",
            "weighted avg       0.65      0.64      0.63       100\n",
            "\n",
            "Multiclass Perceptron with Softmax Accuracy: 0.64\n",
            "Confusion Matrix:\n",
            " [[22  6  0]\n",
            " [17 12  5]\n",
            " [ 3  5 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        28\n",
            "           1       0.52      0.35      0.42        34\n",
            "           2       0.86      0.79      0.82        38\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.63      0.64      0.62       100\n",
            "weighted avg       0.65      0.64      0.63       100\n",
            "\n",
            "Multiclass Perceptron with Softmax Accuracy: 0.64\n",
            "Confusion Matrix:\n",
            " [[22  6  0]\n",
            " [17 12  5]\n",
            " [ 3  5 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        28\n",
            "           1       0.52      0.35      0.42        34\n",
            "           2       0.86      0.79      0.82        38\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.63      0.64      0.62       100\n",
            "weighted avg       0.65      0.64      0.63       100\n",
            "\n",
            "Multiclass Perceptron with Softmax Accuracy: 0.64\n",
            "Confusion Matrix:\n",
            " [[22  6  0]\n",
            " [17 12  5]\n",
            " [ 3  5 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        28\n",
            "           1       0.52      0.35      0.42        34\n",
            "           2       0.86      0.79      0.82        38\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.63      0.64      0.62       100\n",
            "weighted avg       0.65      0.64      0.63       100\n",
            "\n",
            "Multiclass Perceptron with Softmax Accuracy: 0.64\n",
            "Confusion Matrix:\n",
            " [[22  6  0]\n",
            " [17 12  5]\n",
            " [ 3  5 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        28\n",
            "           1       0.52      0.35      0.42        34\n",
            "           2       0.86      0.79      0.82        38\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.63      0.64      0.62       100\n",
            "weighted avg       0.65      0.64      0.63       100\n",
            "\n",
            "Multiclass Perceptron with Softmax Accuracy: 0.64\n",
            "Confusion Matrix:\n",
            " [[22  6  0]\n",
            " [17 12  5]\n",
            " [ 3  5 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        28\n",
            "           1       0.52      0.35      0.42        34\n",
            "           2       0.86      0.79      0.82        38\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.63      0.64      0.62       100\n",
            "weighted avg       0.65      0.64      0.63       100\n",
            "\n",
            "Multiclass Perceptron with Softmax Accuracy: 0.64\n",
            "Confusion Matrix:\n",
            " [[22  6  0]\n",
            " [17 12  5]\n",
            " [ 3  5 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        28\n",
            "           1       0.52      0.35      0.42        34\n",
            "           2       0.86      0.79      0.82        38\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.63      0.64      0.62       100\n",
            "weighted avg       0.65      0.64      0.63       100\n",
            "\n",
            "Multiclass Perceptron with Softmax Accuracy: 0.64\n",
            "Confusion Matrix:\n",
            " [[22  6  0]\n",
            " [17 12  5]\n",
            " [ 3  5 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        28\n",
            "           1       0.52      0.35      0.42        34\n",
            "           2       0.86      0.79      0.82        38\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.63      0.64      0.62       100\n",
            "weighted avg       0.65      0.64      0.63       100\n",
            "\n",
            "Multiclass Perceptron with Softmax Accuracy: 0.64\n",
            "Confusion Matrix:\n",
            " [[22  6  0]\n",
            " [17 12  5]\n",
            " [ 3  5 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        28\n",
            "           1       0.52      0.35      0.42        34\n",
            "           2       0.86      0.79      0.82        38\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.63      0.64      0.62       100\n",
            "weighted avg       0.65      0.64      0.63       100\n",
            "\n",
            "Multiclass Perceptron with Softmax Accuracy: 0.64\n",
            "Confusion Matrix:\n",
            " [[22  6  0]\n",
            " [17 12  5]\n",
            " [ 3  5 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        28\n",
            "           1       0.52      0.35      0.42        34\n",
            "           2       0.86      0.79      0.82        38\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.63      0.64      0.62       100\n",
            "weighted avg       0.65      0.64      0.63       100\n",
            "\n",
            "Multiclass Perceptron with Softmax Accuracy: 0.64\n",
            "Confusion Matrix:\n",
            " [[22  6  0]\n",
            " [17 12  5]\n",
            " [ 3  5 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        28\n",
            "           1       0.52      0.35      0.42        34\n",
            "           2       0.86      0.79      0.82        38\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.63      0.64      0.62       100\n",
            "weighted avg       0.65      0.64      0.63       100\n",
            "\n",
            "Multiclass Perceptron with Softmax Accuracy: 0.64\n",
            "Confusion Matrix:\n",
            " [[22  6  0]\n",
            " [17 12  5]\n",
            " [ 3  5 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.79      0.63        28\n",
            "           1       0.52      0.35      0.42        34\n",
            "           2       0.86      0.79      0.82        38\n",
            "\n",
            "    accuracy                           0.64       100\n",
            "   macro avg       0.63      0.64      0.62       100\n",
            "weighted avg       0.65      0.64      0.63       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X2-gjPHL0lZ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
