{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhSBLWqwTe1y5NgWkleEiT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riiishaab/MLEE/blob/main/MLEE_Exp_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZPhTyQQntly"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import mode"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid"
      ],
      "metadata": {
        "id": "rVMCtemUoMo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1/(1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "VG_16pMUoGJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression for Training"
      ],
      "metadata": {
        "id": "szcZn3mfrUmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch Gradient Descent\n",
        "def train_logistic_regression_BatchGD(X, y, learning_rate, epochs):\n",
        "    samples, features = X.shape\n",
        "    w = np.zeros(features)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        z = np.dot(X, w)\n",
        "        y_pred = sigmoid(z)\n",
        "\n",
        "        # Compute gradient and update weights\n",
        "        gradient = (1 / samples) * np.dot(X.T, (y_pred - y))\n",
        "        w -= learning_rate * gradient\n",
        "\n",
        "    return w\n",
        "\n",
        "# Stochastic Gradient Descent\n",
        "def train_logistic_regression_SGD(X, y, learning_rate, epochs):\n",
        "    samples, features = X.shape\n",
        "    w = np.zeros(features)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Shuffle the data each epoch\n",
        "        shuffled_indices = np.random.permutation(samples)\n",
        "        X_shuffled = X[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        # Update weights for each sample\n",
        "        for i in range(samples):\n",
        "            xi = X_shuffled[i]\n",
        "            yi = y_shuffled[i]\n",
        "\n",
        "            z = np.dot(xi, w)\n",
        "            y_pred = sigmoid(z)\n",
        "\n",
        "            # Compute gradient and update weights\n",
        "            gradient = xi * (y_pred - yi)\n",
        "            w -= learning_rate * gradient\n",
        "\n",
        "    return w\n",
        "\n",
        "# Mini-Batch Gradient Descent\n",
        "def train_logistic_regression_MBGD(X, y, learning_rate, epochs, batch_size=32):\n",
        "    samples, features = X.shape\n",
        "    w = np.zeros(features)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Shuffle the data each epoch\n",
        "        shuffled_indices = np.random.permutation(samples)\n",
        "        X_shuffled = X[shuffled_indices]\n",
        "        y_shuffled = y[shuffled_indices]\n",
        "\n",
        "        # Process mini-batches\n",
        "        for i in range(0, samples, batch_size):\n",
        "            X_batch = X_shuffled[i:i + batch_size]\n",
        "            y_batch = y_shuffled[i:i + batch_size]\n",
        "\n",
        "            z = np.dot(X_batch, w)\n",
        "            y_pred = sigmoid(z)\n",
        "\n",
        "            # Compute gradient and update weights\n",
        "            gradient = (1 / len(X_batch)) * np.dot(X_batch.T, (y_pred - y_batch))\n",
        "            w -= learning_rate * gradient\n",
        "\n",
        "    return w\n"
      ],
      "metadata": {
        "id": "EgNfbfBwobBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression for Testing and Prediction"
      ],
      "metadata": {
        "id": "I-kVa1QGrYx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_logistic_regression(X,w):\n",
        "  z = np.dot(X,w)\n",
        "  y_pred = sigmoid(z)\n",
        "  return np.where(y_pred > 0.5,1,0)"
      ],
      "metadata": {
        "id": "cKHht03OqXn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One v/s All Multi-Class Classification"
      ],
      "metadata": {
        "id": "rzGtrHGLyk22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def train_one_vs_all(X, y, learning_rate, epochs):\n",
        "    classes = len(np.unique(y))\n",
        "    classifiers_BGD = {}\n",
        "    classifiers_SGD = {}\n",
        "    classifiers_MBGD = {}\n",
        "\n",
        "    for c in range(classes):\n",
        "        print(f\"Training Classification Model for Class {c}\")\n",
        "        y_binary = np.where(y == c, 1, 0)\n",
        "\n",
        "        # Train models using each gradient descent approach\n",
        "        w_BatchGD = train_logistic_regression_BatchGD(X, y_binary, learning_rate, epochs)\n",
        "        w_StochasticGD = train_logistic_regression_SGD(X, y_binary, learning_rate, epochs)\n",
        "        w_MBGD = train_logistic_regression_MBGD(X, y_binary, learning_rate, epochs)\n",
        "\n",
        "        # Store weights for each class\n",
        "        classifiers_BGD[c] = w_BatchGD\n",
        "        classifiers_SGD[c] = w_StochasticGD\n",
        "        classifiers_MBGD[c] = w_MBGD\n",
        "\n",
        "    return classifiers_BGD, classifiers_SGD, classifiers_MBGD\n"
      ],
      "metadata": {
        "id": "-ZtoP952rFNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_one_vs_all(X, classifiers):\n",
        "    probabilities = {}\n",
        "\n",
        "    # Compute class probabilities for each classifier\n",
        "    for c, w in classifiers.items():\n",
        "        probabilities[c] = sigmoid(np.dot(X, w))\n",
        "\n",
        "    # Find the class with the highest probability for each sample\n",
        "    predictions = np.array([\n",
        "        max(probabilities, key=lambda k: probabilities[k][i])\n",
        "        for i in range(X.shape[0])\n",
        "    ])\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "dwZyjT0FxrPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One v/s One Multi Class Classification"
      ],
      "metadata": {
        "id": "EE--vAWY3gdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_vs_one(X, y, learning_rate, epochs):\n",
        "    classes = np.unique(y)\n",
        "    classifiers_BGD = []\n",
        "    classifiers_SGD = []\n",
        "    classifiers_MBGD = []\n",
        "    pairs_BGD = []\n",
        "    pairs_SGD = []\n",
        "    pairs_MBGD = []\n",
        "\n",
        "    for i, c1 in enumerate(classes):\n",
        "        for c2 in classes[i+1:]:\n",
        "            idx = np.where((y == c1) | (y == c2))[0]\n",
        "            X_pair = X[idx]\n",
        "            y_pair = np.where(y[idx] == c1, 1, 0)\n",
        "\n",
        "            print(f\"Training {c1} vs {c2} classifier\")\n",
        "\n",
        "            # Train different variants\n",
        "            w_BGD = train_logistic_regression_BatchGD(X_pair, y_pair, learning_rate, epochs)\n",
        "            w_SGD = train_logistic_regression_SGD(X_pair, y_pair, learning_rate, epochs)  # Corrected here\n",
        "            w_MBGD = train_logistic_regression_MBGD(X_pair, y_pair, learning_rate, epochs)\n",
        "\n",
        "            # Store results for each variant\n",
        "            classifiers_BGD.append(w_BGD)\n",
        "            pairs_BGD.append((c1, c2))\n",
        "\n",
        "            classifiers_SGD.append(w_SGD)\n",
        "            pairs_SGD.append((c1, c2))\n",
        "\n",
        "            classifiers_MBGD.append(w_MBGD)\n",
        "            pairs_MBGD.append((c1, c2))\n",
        "\n",
        "    return classifiers_BGD, classifiers_SGD, classifiers_MBGD, pairs_BGD, pairs_SGD, pairs_MBGD\n"
      ],
      "metadata": {
        "id": "6bvDPw8m1hMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_one_vs_one(X, classifiers, pairs):\n",
        "    predictions = []\n",
        "\n",
        "    # Predict class for each classifier\n",
        "    for (c1, c2), weights in zip(pairs, classifiers):\n",
        "        pred = predict_logistic_regression(X, weights)\n",
        "        pred_classes = np.where(pred == 1, c1, c2)\n",
        "        predictions.append(pred_classes)\n",
        "\n",
        "    # Stack predictions and take the mode\n",
        "    predictions = np.array(predictions).T\n",
        "    final_predictions = mode(predictions, axis=1, keepdims=False).mode.flatten()\n",
        "\n",
        "    return final_predictions\n"
      ],
      "metadata": {
        "id": "o-odqjPy3Vl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evalution Metrices"
      ],
      "metadata": {
        "id": "Y4r4rZ5A5OHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report,cohen_kappa_score\n",
        "\n",
        "# Function to evaluate metrics\n",
        "def evaluate_metrics(y_true, y_pred, method_name=\"\"):\n",
        "    print(f\"\\n--- Metrics for {method_name} ---\")\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "    # Precision, Recall, F1-Score\n",
        "    report = classification_report(y_true, y_pred, digits=4)\n",
        "    print(f\"Classification Report:\\n{report}\")\n",
        "    # Kappa Score\n",
        "    kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    print(f\"Kappa Score: {kappa:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Add bias column\n",
        "def add_bias(X):\n",
        "    return np.hstack((X, np.ones((X.shape[0], 1))))\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score\n",
        "\n",
        "# Function to evaluate metrics\n",
        "def evaluate_metrics(y_true, y_pred, method_name=\"\"):\n",
        "    print(f\"\\n--- Metrics for {method_name} ---\")\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "    # Precision, Recall, F1-Score\n",
        "    report = classification_report(y_true, y_pred, digits=4)\n",
        "    print(f\"Classification Report:\\n{report}\")\n",
        "    # Kappa Score\n",
        "    kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    print(f\"Kappa Score: {kappa:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Add bias column\n",
        "def add_bias(X):\n",
        "    return np.hstack((X, np.ones((X.shape[0], 1))))\n",
        "\n",
        "# Example Dataset\n",
        "X, y = make_classification(n_samples=300,\n",
        "                           n_features=5,\n",
        "                           n_classes=3,\n",
        "                           n_informative=3,\n",
        "                           random_state=42)\n",
        "\n",
        "X = add_bias(X)  # Add bias column\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score\n",
        "\n",
        "# Function to evaluate metrics\n",
        "def evaluate_metrics(y_true, y_pred, method_name=\"\"):\n",
        "    print(f\"\\n--- Metrics for {method_name} ---\")\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "    # Precision, Recall, F1-Score\n",
        "    report = classification_report(y_true, y_pred, digits=4)\n",
        "    print(f\"Classification Report:\\n{report}\")\n",
        "    # Kappa Score\n",
        "    kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    print(f\"Kappa Score: {kappa:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Add bias column\n",
        "def add_bias(X):\n",
        "    return np.hstack((X, np.ones((X.shape[0], 1))))\n",
        "\n",
        "# Example Dataset\n",
        "X, y = make_classification(n_samples=300,\n",
        "                           n_features=5,\n",
        "                           n_classes=3,\n",
        "                           n_informative=3,\n",
        "                           random_state=42)\n",
        "\n",
        "X = add_bias(X)  # Add bias column\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Example Dataset\n",
        "X, y = make_classification(n_samples=300, n_features=5, n_classes=3,\n",
        "n_informative=3, random_state=42)\n",
        "X = add_bias(X) # Add bias column\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "iRHkCKo34pyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One v/s All Implementation"
      ],
      "metadata": {
        "id": "_ypdUJI15m8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train one-vs-all classifiers\n",
        "classifiers_BGD, classifiers_SGD, classifiers_MBGD = train_one_vs_all(\n",
        "    X_train, y_train,\n",
        "    learning_rate=0.1, epochs=2000\n",
        ")\n",
        "\n",
        "# Predict with Batch Gradient Descent (BGD)\n",
        "y_pred_BGD = predict_one_vs_all(X_test, classifiers_BGD)\n",
        "print(f\"One-vs-All Accuracy of BGD: {accuracy_score(y_test, y_pred_BGD):.4f}\")\n",
        "\n",
        "# Predict with Stochastic Gradient Descent (SGD)\n",
        "y_pred_SGD = predict_one_vs_all(X_test, classifiers_SGD)\n",
        "print(f\"One-vs-All Accuracy of SGD: {accuracy_score(y_test, y_pred_SGD):.4f}\")\n",
        "\n",
        "# Predict with Mini-Batch Gradient Descent (MBGD)\n",
        "y_pred_MBGD = predict_one_vs_all(X_test, classifiers_MBGD)\n",
        "print(f\"One-vs-All Accuracy of MBGD: {accuracy_score(y_test, y_pred_MBGD):.4f}\")\n",
        "\n",
        "# Evaluate metrics for each variant\n",
        "evaluate_metrics(y_test, y_pred_BGD, method_name=\"One-vs-All-BGD\")\n",
        "evaluate_metrics(y_test, y_pred_SGD, method_name=\"One-vs-All-SGD\")\n",
        "evaluate_metrics(y_test, y_pred_MBGD, method_name=\"One-vs-All-MBGD\")\n"
      ],
      "metadata": {
        "id": "HWapyL3c5NbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f511a76d-22af-478c-f954-e1087855aeee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classification Model for Class 0\n",
            "Training Classification Model for Class 1\n",
            "Training Classification Model for Class 2\n",
            "One-vs-All Accuracy of BGD: 0.6667\n",
            "One-vs-All Accuracy of SGD: 0.6167\n",
            "One-vs-All Accuracy of MBGD: 0.6667\n",
            "\n",
            "--- Metrics for One-vs-All-BGD ---\n",
            "Confusion Matrix:\n",
            "[[16  3  1]\n",
            " [ 6 10  7]\n",
            " [ 3  0 14]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6400    0.8000    0.7111        20\n",
            "           1     0.7692    0.4348    0.5556        23\n",
            "           2     0.6364    0.8235    0.7179        17\n",
            "\n",
            "    accuracy                         0.6667        60\n",
            "   macro avg     0.6819    0.6861    0.6615        60\n",
            "weighted avg     0.6885    0.6667    0.6534        60\n",
            "\n",
            "Kappa Score: 0.5056\n",
            "----------------------------------------\n",
            "\n",
            "--- Metrics for One-vs-All-SGD ---\n",
            "Confusion Matrix:\n",
            "[[12  7  1]\n",
            " [ 6 12  5]\n",
            " [ 3  1 13]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5714    0.6000    0.5854        20\n",
            "           1     0.6000    0.5217    0.5581        23\n",
            "           2     0.6842    0.7647    0.7222        17\n",
            "\n",
            "    accuracy                         0.6167        60\n",
            "   macro avg     0.6185    0.6288    0.6219        60\n",
            "weighted avg     0.6143    0.6167    0.6137        60\n",
            "\n",
            "Kappa Score: 0.4243\n",
            "----------------------------------------\n",
            "\n",
            "--- Metrics for One-vs-All-MBGD ---\n",
            "Confusion Matrix:\n",
            "[[16  3  1]\n",
            " [ 6 10  7]\n",
            " [ 3  0 14]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6400    0.8000    0.7111        20\n",
            "           1     0.7692    0.4348    0.5556        23\n",
            "           2     0.6364    0.8235    0.7179        17\n",
            "\n",
            "    accuracy                         0.6667        60\n",
            "   macro avg     0.6819    0.6861    0.6615        60\n",
            "weighted avg     0.6885    0.6667    0.6534        60\n",
            "\n",
            "Kappa Score: 0.5056\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One v/s One Implementation"
      ],
      "metadata": {
        "id": "XqIhPpNb5sd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train classifiers for one-vs-one\n",
        "classifiers_BGD, classifiers_SGD, classifiers_MBGD, pairs_BGD, pairs_SGD, pairs_MBGD = train_one_vs_one(\n",
        "    X_train, y_train,\n",
        "    learning_rate=0.1, epochs=2000\n",
        ")\n",
        "\n",
        "# Predictions using one-vs-one classifiers\n",
        "y_pred_BGD = predict_one_vs_one(X_test, classifiers_BGD, pairs_BGD)\n",
        "y_pred_SGD = predict_one_vs_one(X_test, classifiers_SGD, pairs_SGD)\n",
        "y_pred_MBGD = predict_one_vs_one(X_test, classifiers_MBGD, pairs_MBGD)\n",
        "\n",
        "# Print accuracies for each method\n",
        "print(f\"One-vs-One Accuracy BGD: {accuracy_score(y_test, y_pred_BGD):.4f}\")\n",
        "print(f\"One-vs-One Accuracy SGD: {accuracy_score(y_test, y_pred_SGD):.4f}\")\n",
        "print(f\"One-vs-One Accuracy MBGD: {accuracy_score(y_test, y_pred_MBGD):.4f}\")\n",
        "\n",
        "# Evaluate metrics for each method\n",
        "evaluate_metrics(y_test, y_pred_BGD, method_name=\"One-vs-One-BGD\")\n",
        "evaluate_metrics(y_test, y_pred_SGD, method_name=\"One-vs-One-SGD\")\n",
        "evaluate_metrics(y_test, y_pred_MBGD, method_name=\"One-vs-One-MBGD\")\n"
      ],
      "metadata": {
        "id": "Zv_WIokB5xQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766bb9a0-7b73-4bee-989c-60faf7247aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training 0 vs 1 classifier\n",
            "Training 0 vs 2 classifier\n",
            "Training 1 vs 2 classifier\n",
            "One-vs-One Accuracy BGD: 0.6333\n",
            "One-vs-One Accuracy SGD: 0.6667\n",
            "One-vs-One Accuracy MBGD: 0.6500\n",
            "\n",
            "--- Metrics for One-vs-One-BGD ---\n",
            "Confusion Matrix:\n",
            "[[13  6  1]\n",
            " [ 4 13  6]\n",
            " [ 3  2 12]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6500    0.6500    0.6500        20\n",
            "           1     0.6190    0.5652    0.5909        23\n",
            "           2     0.6316    0.7059    0.6667        17\n",
            "\n",
            "    accuracy                         0.6333        60\n",
            "   macro avg     0.6335    0.6404    0.6359        60\n",
            "weighted avg     0.6329    0.6333    0.6321        60\n",
            "\n",
            "Kappa Score: 0.4486\n",
            "----------------------------------------\n",
            "\n",
            "--- Metrics for One-vs-One-SGD ---\n",
            "Confusion Matrix:\n",
            "[[15  4  1]\n",
            " [ 6 12  5]\n",
            " [ 4  0 13]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6000    0.7500    0.6667        20\n",
            "           1     0.7500    0.5217    0.6154        23\n",
            "           2     0.6842    0.7647    0.7222        17\n",
            "\n",
            "    accuracy                         0.6667        60\n",
            "   macro avg     0.6781    0.6788    0.6681        60\n",
            "weighted avg     0.6814    0.6667    0.6627        60\n",
            "\n",
            "Kappa Score: 0.5019\n",
            "----------------------------------------\n",
            "\n",
            "--- Metrics for One-vs-One-MBGD ---\n",
            "Confusion Matrix:\n",
            "[[13  6  1]\n",
            " [ 4 14  5]\n",
            " [ 3  2 12]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6500    0.6500    0.6500        20\n",
            "           1     0.6364    0.6087    0.6222        23\n",
            "           2     0.6667    0.7059    0.6857        17\n",
            "\n",
            "    accuracy                         0.6500        60\n",
            "   macro avg     0.6510    0.6549    0.6526        60\n",
            "weighted avg     0.6495    0.6500    0.6495        60\n",
            "\n",
            "Kappa Score: 0.4724\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PxiOyswX7Co7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
